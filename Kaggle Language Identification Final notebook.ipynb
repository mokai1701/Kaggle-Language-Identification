{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Language Identification\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"margin: 20px\">A beloved home South Africa is, with its melting pot of culture, art, tradition and boasts of 11 official languages found spread across all 9 of its Provinces. <br>\n",
    "The purpose of the notebook is to take a journey into the heart and richness of the 11 amazing languages it posseses by creating a classification model that can detect which  of the 11 languages a text could belong... </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "The notebook is a four part composition of how the classification of the texts in the 11 official languages will be carried out:\n",
    "\n",
    "\n",
    "___\n",
    "### Part 1 of the classification approach followed is to  import the neccessary libraries that aid in:\n",
    "- Numerical computation\n",
    "- Data Import and manipulation\n",
    "- Data set split into training and test\n",
    "- Model training and prediction\n",
    "\n",
    "### Part 2 to follow is to import csv files namely of the:\n",
    "- Train set\n",
    "- Test set\n",
    "- Sample sumbission\n",
    "- Analyse the imported data\n",
    "\n",
    "### Part 3 of the notebook is for:\n",
    "- Training\n",
    "- Predictions\n",
    "\n",
    "### Part 4 of the notebook is for:\n",
    "- Model hypertuning:\n",
    "    - Ensemble Methods\n",
    "    - Grid Search\n",
    "    - Predictions\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Import helper libraries\n",
    "\n",
    "The libraries as mentioned are for numerical computation, data analysis and manipulation, training, predicting and scoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jen\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\jen\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\jen\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Part 2: Import data and perform analysis\n",
    "\n",
    "This part of the notebook deals with reading in the data, analysing the data for the types of data types in the datasets, as this guides in the vectorization of features.\n",
    "The above is done because machine learning models cannot train on object type data, therefore during analysis, data types are accounted for.\n",
    "Missing values are also accounted for in the rows and also any whitespaces within the columns.\n",
    "Lastly, the label column classes are checked for data imbalancing to see the distribution of the classes and if any resampling will need to be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets\n",
    "train = pd.read_csv('train_set.csv')\n",
    "test = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the sample_submission file to see how the submission file should look\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Analysis of the train set\n",
    "\n",
    "The first analysis is performed on the train set in the the following cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 5 rows of the test set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the train columns and rows to ensure that 33000 rows and 2 columns are imported\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Summary statistic for checking data types, null_values, number of observations\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code is just to ascertain that null values are indeed 0\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "In data analysis, rows could or could not have missing values, in the case of missing values, pandas methods are used to handle such values in a desired manner. When dealing with text data however, extra caution needs to be taken, as some entries could not report as `NaN` in the summary statistic but could be saved as empty string or white spaces. The code below accounts for such a precaution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list called blanks_list to append any null values saved as empty strings or white spaces\n",
    "blanks_list = []\n",
    "# Iterate over the dataframe to check for whitespaces in the 'text' column\n",
    "for index, label, text in train.itertuples():\n",
    "    if type(text) == str:\n",
    "        if text.isspace():\n",
    "            blanks_list.append(index) # If any whitespaces are found, append their corresponding index\n",
    "                                      # to the blanks_list\n",
    "# There are no white spaces in the 'text' column\n",
    "len(blanks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "#### Full names of the classes in the `lang_df` column of the train set \n",
    "\n",
    "It would be helpful to get the full names of the languges in the `lang_id` column of the train set.\n",
    "\n",
    "Below is the full names of the classes in the `lang_id` column.\n",
    "\n",
    "| Lang_Id       | Language Name       |\n",
    "| ------------- |:-------------------:|\n",
    "| sot           | Sesotho             |\n",
    "| ssw           | siSwati             |\n",
    "| nso           | Sepedi              |\n",
    "| zul           | isiZulu             |\n",
    "| afr           | Afrikaans           |\n",
    "| xho           | isiXhosa            |\n",
    "| tso           | Xitsonga            |\n",
    "| eng           | English             |\n",
    "| tsn           | Setswana            |\n",
    "| nbl           | isiNdebele          |\n",
    "| ven           | Tshivenda           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the frequency distribution of each class in the 'lang_id' column, the label counts are equal\n",
    "train['lang_id'].value_counts().plot(kind = 'bar')\n",
    "plt.xlabel('Language Identity', fontsize = 12)\n",
    "plt.ylabel('Frequency', fontsize = 12)\n",
    "plt.title('Frequency distribution of the classes', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are well balanced with each other and resampling for this dataset will not be needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Analysis of the test set\n",
    "\n",
    "The second analysis is performed on the train set in the the following cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 5 rows of the test set\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5682, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the test columns and rows to ensure that 5682 rows and 2 columns are imported\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   5682 non-null   int64 \n",
      " 1   text    5682 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 88.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Summary statistic for checking data types, null_values, number of observations\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code is just to ascertain that null values are indeed 0\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "As already mentioned above, in data analysis, rows could or could not have missing values, in the case of missing values, pandas methods are used to handle such values in a desired manner. When dealing with text data however, extra caution needs to be taken, as some entries could not report as `NaN` in the summary statistic but could be saved as empty string or white spaces. The code below accounts for such a precaution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list called blanks_list to append any null values saved as empty strings or white spaces\n",
    "blanks_list = []\n",
    "# Iterate over the dataframe to check for whitespaces in the 'text' column\n",
    "for index, label, text in test.itertuples():\n",
    "    if type(text) == str:\n",
    "        if text.isspace():\n",
    "            blanks_list.append(index) # If any whitespaces are found, append their corresponding index\n",
    "                                      # to the blanks_list\n",
    "                \n",
    "                \n",
    "# There are no white spaces in the 'text' column\n",
    "len(blanks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Part 3: Training and Predictions\n",
    "\n",
    "- Training\n",
    "- Predictions\n",
    "___\n",
    "\n",
    "#### Training\n",
    "In this part of the notebook, the train set data is split into **`X`** features, using the 'text' column of the train dataframe and **`y`** labels using the 'lang_df' column of the train dataframe.\n",
    "The data is split as **`25% for the testing set and 75% for the training set with a random_state of 42`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation metric\n",
    "\n",
    "The evaluation metric of the is classification is the **`F1_score`**, depicted with the formula below:\n",
    "\n",
    "\n",
    "$$F_1 = 2 \\times \\frac {Precision \\space \\times \\space Recall }{Precision \\space + \\space Recall }$$\n",
    "\n",
    "\n",
    "\n",
    "According to [deepai.org](https://deepai.org/machine-learning-glossary-and-terms/f-score).The F1_score is a measure of a model’s accuracy on a dataset, and it is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of the model’s precision and recall. \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate X and y\n",
    "X = train['text']\n",
    "y = train['lang_id']\n",
    "\n",
    "# Split the train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "#### The first set of models are trained on their default parameters\n",
    "\n",
    "**Logistic Regression**\n",
    "\n",
    "The first base model to be tested is a `Logistic Regression` model with multi_class set to `one-vs-rest` and will all other parameters set to default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of the Logistic Regression model with default parameters is: 0.9944853939482295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      1.00       754\n",
      "         eng       1.00      1.00      1.00       762\n",
      "         nbl       0.98      0.99      0.99       734\n",
      "         nso       1.00      0.99      1.00       782\n",
      "         sot       1.00      1.00      1.00       759\n",
      "         ssw       0.99      0.99      0.99       732\n",
      "         tsn       1.00      1.00      1.00       746\n",
      "         tso       1.00      1.00      1.00       700\n",
      "         ven       1.00      1.00      1.00       785\n",
      "         xho       0.99      1.00      0.99       761\n",
      "         zul       0.98      0.97      0.98       735\n",
      "\n",
      "    accuracy                           0.99      8250\n",
      "   macro avg       0.99      0.99      0.99      8250\n",
      "weighted avg       0.99      0.99      0.99      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with default params pipeline\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression(multi_class = 'ovr'))])\n",
    "\n",
    "# Fit the model\n",
    "logreg = text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Print the F1_score\n",
    "print('The F1_Score of the Logistic Regression model with default parameters is:',f1_score(y_test, y_pred, average = 'macro'))\n",
    "print()\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Results**:\n",
    "The Logistic Regression as the first model to be submitted returned an `F1_score of 0.88096`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "**Random Forest Classifier**\n",
    "\n",
    "The second model to be tested is a `Random Forest Classifier` model with parameters set to default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of the Random Forest Classifier model with default parameters is: 0.9847108836157633\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       754\n",
      "         eng       0.99      1.00      1.00       762\n",
      "         nbl       0.98      0.95      0.96       734\n",
      "         nso       1.00      0.99      1.00       782\n",
      "         sot       1.00      1.00      1.00       759\n",
      "         ssw       0.99      0.96      0.97       732\n",
      "         tsn       0.99      0.99      0.99       746\n",
      "         tso       1.00      1.00      1.00       700\n",
      "         ven       1.00      1.00      1.00       785\n",
      "         xho       0.98      0.98      0.98       761\n",
      "         zul       0.92      0.96      0.94       735\n",
      "\n",
      "    accuracy                           0.98      8250\n",
      "   macro avg       0.98      0.98      0.98      8250\n",
      "weighted avg       0.99      0.98      0.98      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with default params pipeline\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', RandomForestClassifier())])\n",
    "\n",
    "# Fit the model\n",
    "rfc = text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print the overall accuracy\n",
    "print('The F1_Score of the Random Forest Classifier model with default parameters is:',f1_score(y_test, y_pred, average = 'macro'))\n",
    "print()\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier Results**:\n",
    "The Random Forest Classifier as the second model to be submitted returned an `F1_score of 0.87062`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Support Vector Classifier**\n",
    "\n",
    "The third model to be tested is a `Support Vector Classifier` model with parameters set to default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of the Support Vector Classifier model with default parameters is: 0.9951273633086045\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      1.00       754\n",
      "         eng       1.00      0.99      1.00       762\n",
      "         nbl       0.99      0.99      0.99       734\n",
      "         nso       1.00      0.99      1.00       782\n",
      "         sot       1.00      1.00      1.00       759\n",
      "         ssw       1.00      1.00      1.00       732\n",
      "         tsn       1.00      1.00      1.00       746\n",
      "         tso       1.00      1.00      1.00       700\n",
      "         ven       1.00      1.00      1.00       785\n",
      "         xho       0.99      1.00      0.99       761\n",
      "         zul       0.97      0.99      0.98       735\n",
      "\n",
      "    accuracy                           1.00      8250\n",
      "   macro avg       1.00      1.00      1.00      8250\n",
      "weighted avg       1.00      1.00      1.00      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier with default params pipeline, and kernel = 'rbf'\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', SVC())])\n",
    "\n",
    "# Fit the model\n",
    "model = text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the F1_score\n",
    "print('The F1_Score of the Support Vector Classifier model with default parameters is:',f1_score(y_test, y_pred, average = 'macro'))\n",
    "print()\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Classifier(kernel = 'rbf') Results**:\n",
    "The SVC with kernel set to 'rbf' as the third model to be submitted returned the lowest score thus far with an `F1_score of 0.83726`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Support Vector Classifier**\n",
    "\n",
    "The fourth model to be tested is a `Support Vector Classifier` model with `kernel = 'linear'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of the Support Vector Classifier model with kernel = 'linear' is: 0.9963510578302327\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      1.00       754\n",
      "         eng       1.00      1.00      1.00       762\n",
      "         nbl       0.99      0.99      0.99       734\n",
      "         nso       1.00      0.99      1.00       782\n",
      "         sot       1.00      1.00      1.00       759\n",
      "         ssw       1.00      1.00      1.00       732\n",
      "         tsn       1.00      1.00      1.00       746\n",
      "         tso       1.00      1.00      1.00       700\n",
      "         ven       1.00      1.00      1.00       785\n",
      "         xho       0.99      1.00      0.99       761\n",
      "         zul       0.98      0.99      0.99       735\n",
      "\n",
      "    accuracy                           1.00      8250\n",
      "   macro avg       1.00      1.00      1.00      8250\n",
      "weighted avg       1.00      1.00      1.00      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier with default params pipeline, and kernel = 'linear'\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', SVC(kernel = 'linear'))])\n",
    "\n",
    "# Fit the model\n",
    "model = text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the F1_score\n",
    "print(\"The F1_Score of the Support Vector Classifier model with kernel = 'linear' is:\",f1_score(y_test, y_pred, average = 'macro'))\n",
    "print()\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Classifier(kernel = 'linear') Results**:\n",
    "The SVC with kernel set to 'linear' as the third model to be submitted returned a better score than the rbf, with an `F1_score of 0.85918`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Multinomial Naive Bayes**\n",
    "\n",
    "The fifth model to be tested is the `Multinomial Naive Bayes` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of Multinomial NB with default hyperparameters is: 0.9991517356099913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       754\n",
      "         eng       1.00      1.00      1.00       762\n",
      "         nbl       1.00      1.00      1.00       734\n",
      "         nso       1.00      1.00      1.00       782\n",
      "         sot       1.00      1.00      1.00       759\n",
      "         ssw       1.00      1.00      1.00       732\n",
      "         tsn       1.00      1.00      1.00       746\n",
      "         tso       1.00      1.00      1.00       700\n",
      "         ven       1.00      1.00      1.00       785\n",
      "         xho       1.00      1.00      1.00       761\n",
      "         zul       1.00      1.00      1.00       735\n",
      "\n",
      "    accuracy                           1.00      8250\n",
      "   macro avg       1.00      1.00      1.00      8250\n",
      "weighted avg       1.00      1.00      1.00      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB with default params pipeline\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "# Fit the model\n",
    "mnb = text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "# Print the F1_score\n",
    "print(\"The F1_Score of Multinomial NB with default parameters is:\",f1_score(y_test, y_pred, average = 'macro'))\n",
    "print()\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial NB**:\n",
    "Thus far the Multinomial Naive Bayes has given the best prediction on Kaggle, with an `F1_score of 0.95489`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Prediction on the test set\n",
    "\n",
    "A new dataframe is created that takes in the index from the test dataframe and adds a new column `lang_id` from the predictions of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index\n",
       "0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe, called sub_df that takes the 'index' column from the test dataset\n",
    "sub_df = test[['index']]\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "test_pred = model.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the prediction as a column to the sub_df dataframe\n",
    "sub_df['lang_id'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>zul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>zul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     zul\n",
       "1      2     nbl\n",
       "2      3     ven\n",
       "3      4     ssw\n",
       "4      5     zul"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first few entries to ensure it looks similar to the required sample_submission\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission file\n",
    "sub_df.to_csv('base_submission_mnb.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Model hypertuning\n",
    "\n",
    "### Ensemble methods\n",
    "\n",
    "In a nutshell, ensemble method take a combination of trained models to return a model with the best prediction out of the combination\n",
    "___\n",
    "**Voting Ensemble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of the Voting Classifier model is: 0.9981678584116064\n"
     ]
    }
   ],
   "source": [
    "# Define the three top performing models which we'll be included in the ensemble\n",
    "models = [('LR', logreg), ('RFC',rfc), ('MNB',mnb)]\n",
    "\n",
    "# Specify weights for weighted model averaging\n",
    "model_weightings = np.array([0.25,0.05,0.65])\n",
    "v_clf = VotingClassifier(estimators=models,weights=model_weightings)\n",
    "\n",
    "# Train on the voting classifier\n",
    "v_clf = v_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = v_clf.predict(X_test)\n",
    "\n",
    "# Print F1_score\n",
    "print('The F1_Score of the Voting Classifier model is:',f1_score(y_test, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier voted in favour of the Multinomial NB and returned the same f1_score as the Multinomial NB\n",
    "___\n",
    "**Stacking Ensemble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of the Stacking Classifier model is: 0.9965800360399842\n"
     ]
    }
   ],
   "source": [
    "# Define the three top performing models which we'll be included in the ensemble\n",
    "models = [('LR', logreg), ('RFC',rfc), ('MNB',mnb)]\n",
    "\n",
    "# Declare meta_learner\n",
    "mnb_meta = MultinomialNB()\n",
    "\n",
    "# Instance for the stacking classifier\n",
    "s_clf = StackingClassifier(estimators=models, final_estimator=mnb_meta)\n",
    "\n",
    "# Fit the model\n",
    "s_clf = s_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = s_clf.predict(X_test)\n",
    "\n",
    "# Print the F1_score\n",
    "print('The F1_Score of the Stacking Classifier model is:',f1_score(y_test, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking brought the same F1_score lower as voting. Multinomial NB is the model in favour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble methods, both of them used with default parameters did not improve the Kaggle F1_score\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with GridSearchCV\n",
    "\n",
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of the Random Forest Classifier model with GridSearchCV is: 0.9605152201954077\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       754\n",
      "         eng       0.99      1.00      0.99       762\n",
      "         nbl       0.85      0.92      0.88       734\n",
      "         nso       1.00      0.99      1.00       782\n",
      "         sot       1.00      1.00      1.00       759\n",
      "         ssw       0.94      0.88      0.91       732\n",
      "         tsn       0.99      1.00      0.99       746\n",
      "         tso       0.99      1.00      0.99       700\n",
      "         ven       1.00      1.00      1.00       785\n",
      "         xho       0.93      0.92      0.92       761\n",
      "         zul       0.89      0.86      0.88       735\n",
      "\n",
      "    accuracy                           0.96      8250\n",
      "   macro avg       0.96      0.96      0.96      8250\n",
      "weighted avg       0.96      0.96      0.96      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of parameters\n",
    "rfc_params = {'n_estimators': [5, 25, 50, 75, 100],\n",
    "              'max_depth': [5, 10, 15, 20, 25],\n",
    "              'random_state':[42]}\n",
    "\n",
    "# Pipeline\n",
    "pipe_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', RandomForestClassifier())])\n",
    "\n",
    "# GridSearchCV for Random Forest\n",
    "grfc = GridSearchCV(pipe_clf(), param_grid = rfc_params, cv = 5, n_jobs= -1)\n",
    "\n",
    "# Fit the model\n",
    "rfc = grfc.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print the overall accuracy\n",
    "print('The F1_Score of the Random Forest Classifier model with GridSearchCV is:',f1_score(y_test, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV gives an error for the pipeline on Logistic Regression and Multinomial NB, the following hyperparameters were tuned without it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of the Logistic Regression model with custom C is: 0.9873908525483647\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      0.99      1.00       754\n",
      "         eng       1.00      1.00      1.00       762\n",
      "         nbl       0.96      0.98      0.97       734\n",
      "         nso       1.00      0.98      0.99       782\n",
      "         sot       1.00      1.00      1.00       759\n",
      "         ssw       0.98      0.99      0.99       732\n",
      "         tsn       0.99      0.99      0.99       746\n",
      "         tso       1.00      1.00      1.00       700\n",
      "         ven       1.00      1.00      1.00       785\n",
      "         xho       0.97      0.99      0.98       761\n",
      "         zul       0.97      0.94      0.95       735\n",
      "\n",
      "    accuracy                           0.99      8250\n",
      "   macro avg       0.99      0.99      0.99      8250\n",
      "weighted avg       0.99      0.99      0.99      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with custom C parameter pipeline\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression(C = 0.1, multi_class = 'ovr'))])\n",
    "\n",
    "# Fit the model\n",
    "logreg = text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Print the F1_score\n",
    "print('The F1_Score of the Logistic Regression model with custom C is:',f1_score(y_test, y_pred, average = 'macro'))\n",
    "print()\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial NB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_Score of Multinomial NB with default hyperparameters is: 0.9991517356099913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       754\n",
      "         eng       1.00      1.00      1.00       762\n",
      "         nbl       1.00      1.00      1.00       734\n",
      "         nso       1.00      1.00      1.00       782\n",
      "         sot       1.00      1.00      1.00       759\n",
      "         ssw       1.00      1.00      1.00       732\n",
      "         tsn       1.00      1.00      1.00       746\n",
      "         tso       1.00      1.00      1.00       700\n",
      "         ven       1.00      1.00      1.00       785\n",
      "         xho       1.00      1.00      1.00       761\n",
      "         zul       1.00      1.00      1.00       735\n",
      "\n",
      "    accuracy                           1.00      8250\n",
      "   macro avg       1.00      1.00      1.00      8250\n",
      "weighted avg       1.00      1.00      1.00      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB with custom alpha parameter pipeline\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB(alpha =  0.1))])\n",
    "\n",
    "# Fit the model\n",
    "mnb = text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "# Print the F1_score\n",
    "print(\"The F1_Score of Multinomial NB with alpha = 0.1 is:\",f1_score(y_test, y_pred, average = 'macro'))\n",
    "print()\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index\n",
       "0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe, called sub_df that takes the 'index' column from the test dataset\n",
    "sub_df = test[['index']]\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "test_pred = v_clf.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the prediction as a column to the sub_df dataframe\n",
    "sub_df['lang_id'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl\n",
       "2      3     ven\n",
       "3      4     ssw\n",
       "4      5     afr"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first few entries to ensure it looks similar to the required sample_submission\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission file\n",
    "sub_df.to_csv('base_submission_mnba.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "After hyperparameter tuning, the models did not lower or improve the score on Kaggle, all kept returning the same score of 0.95489, therefore the Kaggle final score is `F1_score: 0.95489`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
